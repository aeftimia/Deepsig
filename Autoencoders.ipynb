{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoders: Dimensionality Reduction, Generation, and Clustering\n",
    "\n",
    "Alex Eftimiades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Use Autoencoders?\n",
    "* Denoising\n",
    "* Dimensionality reduction\n",
    "* Generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoders Tested\n",
    "* Vanilla\n",
    "* Double\n",
    "* Variational\n",
    "* Variational with batch sample estimated kl loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building Blocks\n",
    "\n",
    "* Preprocess: Rescale [0, max] to [0, 1]\n",
    "* Convolutional: RELU\n",
    "* Dense: RELU, linear bottleneck layer\n",
    "* Inverse convolutional: RELU\n",
    "* Mean squared error (gaurantees finite penalities)\n",
    "* Similar results from binary cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyperparameters\n",
    "\n",
    "* batch size: 128\n",
    "* num epochs:  40\n",
    "* kernel size: 4\n",
    "* bottleneck: 2, 32\n",
    "* strides = 2\n",
    "* layer filters = (32, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Base Model\n",
    "\n",
    "<img src=\"http://localhost:8888/files/deepsig/vanilla/encoder_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vanilla\n",
    "\n",
    "<img src=\"http://localhost:8888/files/deepsig/vanilla/digits_over_latent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Double\n",
    "\n",
    "* Vanilla plus reconstruct latent hidden variables\n",
    "* Sampled from independent isotropic unit gaussians\n",
    "* 10 sets of epochs run alternating between ecoder(decoder) and decoder(encoder)\n",
    "* MSE validation loss of vanilla remains similar\n",
    "\n",
    "<img src=\"http://localhost:8888/files/deepsig/double/digits_over_latent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variational\n",
    "\n",
    "* Extra loss acts as regularizer that forces latent distributions to unit gaussians\n",
    "* Keeps latent distributions close to independent unit gaussians\n",
    "* 2 dimensional bottleneck sufficient for generation, not reconstruction\n",
    "\n",
    "<img src=\"http://localhost:8888/files/deepsig/variational/digits_over_latent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variational With Sample Estimated Loss\n",
    "\n",
    "* Latent kl loss derived from estimators over each batch\n",
    "* Regularizer no longer obviously detracts reconstruction fidelity\n",
    "* Ultimately produced similar results to usual variational implementation\n",
    "\n",
    "<img src=\"http://localhost:8888/files/deepsig/variational_sample/digits_over_latent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reconstruction Comparison 2D Bottleneck\n",
    "\n",
    "<img src=\"http://localhost:8888/files/deepsig/reconstructed_2.png\">\n",
    "\n",
    "Note the models' worst reconstructions are a realistic looking wrong number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reconstruction Comparison 32D Bottleneck\n",
    "\n",
    "<img src=\"http://localhost:8888/files/deepsig/reconstructed_32.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# K-means Clustering Accuracy 2D Bottleneck\n",
    "\n",
    "* Vanilla: 61.71%\n",
    "* Double: 55.26%\n",
    "* Variational: 17.13%\n",
    "* Variational Sample Loss: 49.78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# K-means Clustering Accuracy 32D Bottleneck\n",
    "\n",
    "* Vanilla: 85.0%\n",
    "* Double: 85.12%\n",
    "* Variational: 36.52%\n",
    "* Variational Sample Loss: 76.17%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GMM Clustering Accuracy 2D Bottleneck\n",
    "\n",
    "* Vanilla: 61.67%\n",
    "* Double: 54.67%\n",
    "* Variational: 11.36%\n",
    "* Variational Sample Loss: 39.47%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GMM Clustering Accuracy 32D Bottleneck\n",
    "\n",
    "* Vanilla: 83.64%\n",
    "* Double: 82.87%\n",
    "* Variational: 13.67%\n",
    "* Variational Sample Loss: 49.65%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clustering\n",
    "\n",
    "* Vanilla and Double do comparably well for clustering\n",
    "* GMM type analysis may be useful when categories are not mutually exclusive\n",
    "* May be useful for detecting new objects given few examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Future Directions\n",
    "\n",
    "* Resnet blocks\n",
    "* Mainstream image processing networks (Renset, VGG, etc)\n",
    "* Multiclass identification\n",
    "* Further analysis on diverse color images like CIFAR10\n",
    "* Softmax output with normalized input\n",
    "* Combine double and variational with sample estimated loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions/Demo time!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
